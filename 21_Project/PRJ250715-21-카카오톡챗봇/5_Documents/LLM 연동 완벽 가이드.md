---
Created_date: 2025-10-17
Last_Modified_date: 2025-10-17
Version: 1.0
Status: Active
Category: technical-guide
Priority: high
tags:
  - llm
  - openai
  - claude
  - gemini
  - kakao-chatbot
  - api-integration
  - rag
---

# ì¹´ì¹´ì˜¤í†¡ ì±—ë´‡ì— LLM ì—°ë™ ì™„ë²½ ê°€ì´ë“œ

> ì¹´ì¹´ì˜¤ i ì˜¤í”ˆë¹Œë” ì±—ë´‡ì— OpenAI, Claude, Gemini ë“± LLMì„ ì—°ë™í•˜ì—¬ ì§€ëŠ¥í˜• ëŒ€í™” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ì™„ì „í•œ ê°€ì´ë“œ

---

## ğŸ“‹ ëª©ì°¨

1. [LLM ì—°ë™ ê°œìš”](#llm-ì—°ë™-ê°œìš”)
2. [ì•„í‚¤í…ì²˜ ì„¤ê³„](#ì•„í‚¤í…ì²˜-ì„¤ê³„)
3. [OpenAI GPT ì—°ë™](#openai-gpt-ì—°ë™)
4. [Claude ì—°ë™](#claude-ì—°ë™)
5. [Gemini ì—°ë™](#gemini-ì—°ë™)
6. [RAG ì‹œìŠ¤í…œê³¼ LLM ê²°í•©](#rag-ì‹œìŠ¤í…œê³¼-llm-ê²°í•©)
7. [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§](#í”„ë¡¬í”„íŠ¸-ì—”ì§€ë‹ˆì–´ë§)
8. [ë¹„ìš© ìµœì í™”](#ë¹„ìš©-ìµœì í™”)
9. [ë³´ì•ˆ ë° ëª¨ë‹ˆí„°ë§](#ë³´ì•ˆ-ë°-ëª¨ë‹ˆí„°ë§)

---

## LLM ì—°ë™ ê°œìš”

### ì™œ LLMì„ ì—°ë™í•´ì•¼ í•˜ë‚˜ìš”?

**ì¹´ì¹´ì˜¤ i ì˜¤í”ˆë¹Œë” ê¸°ë³¸ ê¸°ëŠ¥ì˜ í•œê³„:**
- ì‚¬ì „ ì •ì˜ëœ ì‹œë‚˜ë¦¬ì˜¤ì™€ ë¸”ë¡ êµ¬ì¡°ì— ì˜ì¡´
- ì˜ˆìƒì¹˜ ëª»í•œ ì§ˆë¬¸ì— ëŒ€ì‘ ì–´ë ¤ì›€
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ êµ¬í˜„ ì œí•œì 
- ë³µì¡í•œ ë¬¸ë§¥ ì´í•´ ë¶ˆê°€ëŠ¥

**LLM ì—°ë™ ì‹œ ì¥ì :**
- âœ… ìì—°ì–´ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥ ëŒ€í­ í–¥ìƒ
- âœ… ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ì§ˆë¬¸ì—ë„ ìœ ì—°í•œ ëŒ€ì‘
- âœ… ë§¥ë½ì„ ì´í•´í•˜ëŠ” ë©€í‹°í„´ ëŒ€í™”
- âœ… RAGì™€ ê²°í•©í•˜ì—¬ ì •í™•í•œ ê¸°ìˆ  ì§€ì› ì œê³µ
- âœ… ì§€ì†ì ì¸ í•™ìŠµ ë° ê°œì„  ê°€ëŠ¥

### LLM ì„ íƒ ê°€ì´ë“œ

| LLM | ì¥ì  | ë‹¨ì  | ì¶”ì²œ ìš©ë„ |
|-----|------|------|-----------|
| **OpenAI GPT-4** | ê°€ì¥ ê°•ë ¥í•œ ì„±ëŠ¥, í’ë¶€í•œ ë¬¸ì„œ | ë¹„ìš© ë†’ìŒ, ì‘ë‹µ ëŠë¦¼ | ë³µì¡í•œ ê¸°ìˆ  ë¬¸ì˜ |
| **OpenAI GPT-3.5** | ë¹ ë¥¸ ì†ë„, ì €ë ´í•œ ë¹„ìš© | ì„±ëŠ¥ ì œí•œì  | ê°„ë‹¨í•œ FAQ |
| **Claude 3 Opus** | ê¸´ ì»¨í…ìŠ¤íŠ¸(200K), ì•ˆì „ì„± ë†’ìŒ | ë¹„ìš© ë†’ìŒ | ë§¤ë‰´ì–¼ ì „ì²´ ì°¸ì¡° |
| **Claude 3 Sonnet** | ê· í˜•ì¡íŒ ì„±ëŠ¥/ë¹„ìš© | - | ì¼ë°˜ì ì¸ ê³ ê° ì§€ì› |
| **Gemini 1.5 Pro** | ë§¤ìš° ê¸´ ì»¨í…ìŠ¤íŠ¸(2M), ë¬´ë£Œ í• ë‹¹ëŸ‰ | í•œêµ­ì–´ ì„±ëŠ¥ ë³´í†µ | ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ |
| **Llama 3** | ìì²´ í˜¸ìŠ¤íŒ…, ë¹„ìš© ë¬´ë£Œ | ì¸í”„ë¼ í•„ìš”, ì„±ëŠ¥ ë‚®ìŒ | ë¹„ìš© ë¯¼ê°í•œ ê²½ìš° |

**ë‹¤ë¹›ì†”ë£¨ì…˜ ì¶”ì²œ ì¡°í•©:**
- **1ì°¨ ì‘ë‹µ**: Claude 3 Sonnet (ë¹ ë¥¸ ì†ë„ + í•œêµ­ì–´ ì„±ëŠ¥)
- **ë³µì¡í•œ ë¬¸ì œ**: GPT-4 (ì •í™•ë„ ìµœìš°ì„ )
- **ì§€ì‹ ê²€ìƒ‰**: RAG (ë²¡í„° DB) + Claude/GPT

---

## ì•„í‚¤í…ì²˜ ì„¤ê³„

### ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°

```mermaid
graph TB
    A[ì¹´ì¹´ì˜¤í†¡ ì‚¬ìš©ì] -->|ë©”ì‹œì§€| B[ì¹´ì¹´ì˜¤ i ì˜¤í”ˆë¹Œë”]
    B -->|Webhook| C[API ì„œë²„ Node.js/Python]
    
    C -->|ì˜ë„ ë¶„ë¥˜| D{ë¼ìš°íŒ… ë¡œì§}
    
    D -->|ê°„ë‹¨í•œ FAQ| E[ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ]
    D -->|ê¸°ìˆ  ë¬¸ì˜| F[RAG ê²€ìƒ‰]
    D -->|ë³µì¡í•œ ì§ˆë¬¸| G[LLM ì²˜ë¦¬]
    
    F -->|ê´€ë ¨ ë¬¸ì„œ| H[ë²¡í„° DB]
    H -->|ì»¨í…ìŠ¤íŠ¸| G
    
    G -->|GPT-4| I[OpenAI API]
    G -->|Claude| J[Anthropic API]
    G -->|Gemini| K[Google AI API]
    
    I --> L[ì‘ë‹µ ìƒì„±]
    J --> L
    K --> L
    
    L -->|Response| C
    C -->|ë‹µë³€| B
    B -->|ë©”ì‹œì§€| A
    
    M[ë¡œê¹… ì‹œìŠ¤í…œ] -.->|ëª¨ë‹ˆí„°ë§| C
    N[ìºì‹œ Redis] -.->|ìºì‹±| C
```

### ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
dabit-chatbot-server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ kakaoController.js      # ì¹´ì¹´ì˜¤ ì›¹í›… ì²˜ë¦¬
â”‚   â”‚   â””â”€â”€ chatController.js       # ëŒ€í™” ë¡œì§
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llmService.js           # LLM í†µí•© ì„œë¹„ìŠ¤
â”‚   â”‚   â”œâ”€â”€ openaiService.js        # OpenAI ì—°ë™
â”‚   â”‚   â”œâ”€â”€ claudeService.js        # Claude ì—°ë™
â”‚   â”‚   â”œâ”€â”€ geminiService.js        # Gemini ì—°ë™
â”‚   â”‚   â””â”€â”€ ragService.js           # RAG ê²€ìƒ‰
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ conversation.js         # ëŒ€í™” ì´ë ¥ ëª¨ë¸
â”‚   â”‚   â””â”€â”€ knowledge.js            # ì§€ì‹ ë² ì´ìŠ¤ ëª¨ë¸
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ promptBuilder.js        # í”„ë¡¬í”„íŠ¸ ìƒì„±
â”‚   â”‚   â”œâ”€â”€ cache.js                # ìºì‹± ìœ í‹¸
â”‚   â”‚   â””â”€â”€ logger.js               # ë¡œê¹…
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ env.js                  # í™˜ê²½ ë³€ìˆ˜
â”‚       â””â”€â”€ prompts.js              # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
â”œâ”€â”€ .env
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

---

## OpenAI GPT ì—°ë™

### 1. í™˜ê²½ ì„¤ì •

#### API í‚¤ ë°œê¸‰
1. https://platform.openai.com/ ì ‘ì†
2. íšŒì›ê°€ì… ë° ë¡œê·¸ì¸
3. API Keys ë©”ë‰´ì—ì„œ ìƒˆ í‚¤ ìƒì„±
4. ê²°ì œ ì •ë³´ ë“±ë¡ (ì¢…ëŸ‰ì œ)

#### íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
npm install openai
# ë˜ëŠ”
pip install openai
```

#### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```env
# .env
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=1000
```

### 2. OpenAI Service êµ¬í˜„ (Node.js)

```javascript
// src/services/openaiService.js
const OpenAI = require('openai');

class OpenAIService {
    constructor() {
        this.client = new OpenAI({
            apiKey: process.env.OPENAI_API_KEY
        });
        
        this.model = process.env.OPENAI_MODEL || 'gpt-4-turbo-preview';
        this.temperature = parseFloat(process.env.OPENAI_TEMPERATURE) || 0.7;
        this.maxTokens = parseInt(process.env.OPENAI_MAX_TOKENS) || 1000;
    }

    /**
     * ë‹¨ì¼ ë©”ì‹œì§€ ì²˜ë¦¬
     */
    async generateResponse(userMessage, systemPrompt = null, context = null) {
        try {
            const messages = [];
            
            // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
            if (systemPrompt) {
                messages.push({
                    role: 'system',
                    content: systemPrompt
                });
            }
            
            // ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ (RAG ê²€ìƒ‰ ê²°ê³¼)
            if (context && context.length > 0) {
                const contextText = this._formatContext(context);
                messages.push({
                    role: 'system',
                    content: `ë‹¤ìŒì€ ì°¸ê³ í•  ê¸°ìˆ  ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤:\n\n${contextText}`
                });
            }
            
            // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.push({
                role: 'user',
                content: userMessage
            });
            
            console.log('[OpenAI] ìš”ì²­:', {
                model: this.model,
                messageCount: messages.length
            });
            
            const response = await this.client.chat.completions.create({
                model: this.model,
                messages: messages,
                temperature: this.temperature,
                max_tokens: this.maxTokens,
                top_p: 1,
                frequency_penalty: 0,
                presence_penalty: 0
            });
            
            const answer = response.choices[0].message.content;
            const usage = response.usage;
            
            console.log('[OpenAI] ì‘ë‹µ ì™„ë£Œ:', {
                tokens: usage.total_tokens,
                cost: this._calculateCost(usage)
            });
            
            return {
                answer: answer,
                model: this.model,
                usage: usage,
                cost: this._calculateCost(usage)
            };
            
        } catch (error) {
            console.error('[OpenAI] ì˜¤ë¥˜:', error);
            throw new Error(`OpenAI API ì˜¤ë¥˜: ${error.message}`);
        }
    }

    /**
     * ëŒ€í™” ì´ë ¥ í¬í•¨ ë©€í‹°í„´ ëŒ€í™”
     */
    async chat(conversationHistory, newMessage, systemPrompt = null) {
        try {
            const messages = [];
            
            // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            if (systemPrompt) {
                messages.push({
                    role: 'system',
                    content: systemPrompt
                });
            }
            
            // ëŒ€í™” ì´ë ¥ ì¶”ê°€ (ìµœê·¼ 5í„´ë§Œ)
            const recentHistory = conversationHistory.slice(-5);
            messages.push(...recentHistory);
            
            // ìƒˆ ë©”ì‹œì§€
            messages.push({
                role: 'user',
                content: newMessage
            });
            
            const response = await this.client.chat.completions.create({
                model: this.model,
                messages: messages,
                temperature: this.temperature,
                max_tokens: this.maxTokens
            });
            
            return {
                answer: response.choices[0].message.content,
                usage: response.usage
            };
            
        } catch (error) {
            console.error('[OpenAI Chat] ì˜¤ë¥˜:', error);
            throw error;
        }
    }

    /**
     * ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ì‹¤ì‹œê°„ í‘œì‹œ)
     */
    async *streamResponse(userMessage, systemPrompt = null) {
        const messages = [
            { role: 'system', content: systemPrompt || 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê¸°ìˆ  ì§€ì› AIì…ë‹ˆë‹¤.' },
            { role: 'user', content: userMessage }
        ];
        
        const stream = await this.client.chat.completions.create({
            model: this.model,
            messages: messages,
            temperature: this.temperature,
            max_tokens: this.maxTokens,
            stream: true
        });
        
        for await (const chunk of stream) {
            const content = chunk.choices[0]?.delta?.content || '';
            if (content) {
                yield content;
            }
        }
    }

    /**
     * ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
     */
    _formatContext(contextArray) {
        return contextArray.map((item, index) => {
            return `[ë¬¸ì„œ ${index + 1}]\n${item.content}\nì¶œì²˜: ${item.source || 'ë§¤ë‰´ì–¼'}`;
        }).join('\n\n---\n\n');
    }

    /**
     * ë¹„ìš© ê³„ì‚° (GPT-4 ê¸°ì¤€)
     */
    _calculateCost(usage) {
        // GPT-4-turbo ê°€ê²© (2024ë…„ ê¸°ì¤€)
        const inputCostPer1K = 0.01;   // $0.01 per 1K tokens
        const outputCostPer1K = 0.03;  // $0.03 per 1K tokens
        
        const inputCost = (usage.prompt_tokens / 1000) * inputCostPer1K;
        const outputCost = (usage.completion_tokens / 1000) * outputCostPer1K;
        
        return {
            total: inputCost + outputCost,
            currency: 'USD',
            breakdown: {
                input: inputCost,
                output: outputCost
            }
        };
    }

    /**
     * Function Calling (ë„êµ¬ ì‚¬ìš©)
     */
    async callWithFunctions(userMessage, functions) {
        const messages = [
            { role: 'user', content: userMessage }
        ];
        
        const response = await this.client.chat.completions.create({
            model: this.model,
            messages: messages,
            functions: functions,
            function_call: 'auto'
        });
        
        const message = response.choices[0].message;
        
        // Function callì´ í•„ìš”í•œ ê²½ìš°
        if (message.function_call) {
            return {
                type: 'function_call',
                function: message.function_call.name,
                arguments: JSON.parse(message.function_call.arguments)
            };
        }
        
        // ì¼ë°˜ ì‘ë‹µ
        return {
            type: 'text',
            content: message.content
        };
    }
}

module.exports = new OpenAIService();
```

### 3. Python ë²„ì „ (FastAPI)

```python
# src/services/openai_service.py
from openai import OpenAI
import os
from typing import List, Dict, Optional
import json

class OpenAIService:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.model = os.getenv('OPENAI_MODEL', 'gpt-4-turbo-preview')
        self.temperature = float(os.getenv('OPENAI_TEMPERATURE', '0.7'))
        self.max_tokens = int(os.getenv('OPENAI_MAX_TOKENS', '1000'))
    
    async def generate_response(
        self,
        user_message: str,
        system_prompt: Optional[str] = None,
        context: Optional[List[Dict]] = None
    ) -> Dict:
        """
        ë‹¨ì¼ ë©”ì‹œì§€ ì²˜ë¦¬
        """
        try:
            messages = []
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            if system_prompt:
                messages.append({
                    'role': 'system',
                    'content': system_prompt
                })
            
            # RAG ì»¨í…ìŠ¤íŠ¸
            if context:
                context_text = self._format_context(context)
                messages.append({
                    'role': 'system',
                    'content': f'ë‹¤ìŒì€ ì°¸ê³ í•  ê¸°ìˆ  ë¬¸ì„œì…ë‹ˆë‹¤:\n\n{context_text}'
                })
            
            # ì‚¬ìš©ì ë©”ì‹œì§€
            messages.append({
                'role': 'user',
                'content': user_message
            })
            
            # API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )
            
            answer = response.choices[0].message.content
            usage = response.usage
            
            return {
                'answer': answer,
                'model': self.model,
                'usage': {
                    'prompt_tokens': usage.prompt_tokens,
                    'completion_tokens': usage.completion_tokens,
                    'total_tokens': usage.total_tokens
                },
                'cost': self._calculate_cost(usage)
            }
            
        except Exception as e:
            print(f'[OpenAI] ì˜¤ë¥˜: {e}')
            raise Exception(f'OpenAI API ì˜¤ë¥˜: {str(e)}')
    
    async def chat(
        self,
        conversation_history: List[Dict],
        new_message: str,
        system_prompt: Optional[str] = None
    ) -> Dict:
        """
        ëŒ€í™” ì´ë ¥ í¬í•¨ ë©€í‹°í„´ ëŒ€í™”
        """
        messages = []
        
        if system_prompt:
            messages.append({
                'role': 'system',
                'content': system_prompt
            })
        
        # ìµœê·¼ 5í„´ë§Œ
        messages.extend(conversation_history[-5:])
        messages.append({
            'role': 'user',
            'content': new_message
        })
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=self.temperature,
            max_tokens=self.max_tokens
        )
        
        return {
            'answer': response.choices[0].message.content,
            'usage': response.usage
        }
    
    async def stream_response(self, user_message: str, system_prompt: Optional[str] = None):
        """
        ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
        """
        messages = [
            {'role': 'system', 'content': system_prompt or 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê¸°ìˆ  ì§€ì› AIì…ë‹ˆë‹¤.'},
            {'role': 'user', 'content': user_message}
        ]
        
        stream = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=self.temperature,
            max_tokens=self.max_tokens,
            stream=True
        )
        
        for chunk in stream:
            content = chunk.choices[0].delta.content
            if content:
                yield content
    
    def _format_context(self, context_array: List[Dict]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
        formatted = []
        for i, item in enumerate(context_array):
            source = item.get('source', 'ë§¤ë‰´ì–¼')
            content = item.get('content', '')
            formatted.append(f'[ë¬¸ì„œ {i+1}]\n{content}\nì¶œì²˜: {source}')
        
        return '\n\n---\n\n'.join(formatted)
    
    def _calculate_cost(self, usage) -> Dict:
        """ë¹„ìš© ê³„ì‚°"""
        input_cost_per_1k = 0.01
        output_cost_per_1k = 0.03
        
        input_cost = (usage.prompt_tokens / 1000) * input_cost_per_1k
        output_cost = (usage.completion_tokens / 1000) * output_cost_per_1k
        
        return {
            'total': input_cost + output_cost,
            'currency': 'USD',
            'breakdown': {
                'input': input_cost,
                'output': output_cost
            }
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
openai_service = OpenAIService()
```

### 4. ì¹´ì¹´ì˜¤ ì˜¤í”ˆë¹Œë” ìŠ¤í‚¬ ì—°ë™

```javascript
// src/controllers/kakaoController.js
const openaiService = require('../services/openaiService');
const ragService = require('../services/ragService');

/**
 * ì¹´ì¹´ì˜¤ ìŠ¤í‚¬ ì—”ë“œí¬ì¸íŠ¸
 */
exports.handleSkill = async (req, res) => {
    try {
        const userMessage = req.body.action.params.userMessage;
        const userId = req.body.userRequest.user.id;
        
        console.log(`[ì¹´ì¹´ì˜¤] ì‚¬ìš©ì ${userId}: ${userMessage}`);
        
        // 1. RAGë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        const relevantDocs = await ragService.search(userMessage, 3);
        
        // 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        const systemPrompt = `
ë‹¹ì‹ ì€ ë‹¤ë¹›ì†”ë£¨ì…˜ì˜ ê¸°ìˆ  ì§€ì› AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**íšŒì‚¬ ì •ë³´:**
- ì „ê´‘íŒ ì»¨íŠ¸ë¡¤ëŸ¬ ì œì¡°ì‚¬
- ì£¼ìš” ì œí’ˆ: DB300, DB400, DB320WB
- ì£¼ìš” ê³ ê°: ì£¼ì°¨ê´€ì œ, ë¶ˆë²•ì£¼ì •ì°¨ ë‹¨ì† ì‹œìŠ¤í…œ

**ì‘ë‹µ ê·œì¹™:**
1. ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€
2. ì œê³µëœ ê¸°ìˆ  ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
3. í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ "ìƒë‹´ì› ì—°ê²°"ì„ ê¶Œìœ 
4. ê°„ê²°í•˜ê²Œ 3-4ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€
5. í•„ìš”ì‹œ ë‹¨ê³„ë³„ ê°€ì´ë“œ ì œê³µ

**ê¸ˆì§€ ì‚¬í•­:**
- ì—†ëŠ” ì •ë³´ ì§€ì–´ë‚´ê¸°
- ê²½ìŸì‚¬ ì œí’ˆ ì–¸ê¸‰
- ê°œì¸ì •ë³´ ìš”êµ¬
        `.trim();
        
        // 3. OpenAIë¡œ ì‘ë‹µ ìƒì„±
        const result = await openaiService.generateResponse(
            userMessage,
            systemPrompt,
            relevantDocs
        );
        
        // 4. ì¹´ì¹´ì˜¤ ì‘ë‹µ í¬ë§·
        const kakaoResponse = {
            version: '2.0',
            template: {
                outputs: [
                    {
                        simpleText: {
                            text: result.answer
                        }
                    }
                ],
                quickReplies: [
                    {
                        label: 'ì¶”ê°€ ë¬¸ì˜',
                        action: 'message',
                        messageText: 'ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆì–´ìš”'
                    },
                    {
                        label: 'ìƒë‹´ì› ì—°ê²°',
                        action: 'message',
                        messageText: 'ìƒë‹´ì›ê³¼ í†µí™”í•˜ê³  ì‹¶ì–´ìš”'
                    },
                    {
                        label: 'ì²˜ìŒìœ¼ë¡œ',
                        action: 'block',
                        blockId: 'WELCOME_BLOCK_ID'
                    }
                ]
            }
        };
        
        // 5. ë¡œê¹…
        await logConversation({
            userId,
            question: userMessage,
            answer: result.answer,
            model: result.model,
            cost: result.cost,
            timestamp: new Date()
        });
        
        res.json(kakaoResponse);
        
    } catch (error) {
        console.error('[ì¹´ì¹´ì˜¤ ìŠ¤í‚¬] ì˜¤ë¥˜:', error);
        
        // ì—ëŸ¬ ì‘ë‹µ
        res.json({
            version: '2.0',
            template: {
                outputs: [
                    {
                        simpleText: {
                            text: 'ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
                        }
                    }
                ]
            }
        });
    }
};
```

### 5. ì¹´ì¹´ì˜¤ ì˜¤í”ˆë¹Œë” ì„¤ì •

1. **ìŠ¤í‚¬ ì„œë²„ ë“±ë¡:**
   - ì˜¤í”ˆë¹Œë” > ì„¤ì • > ìŠ¤í‚¬ ì„œë²„
   - URL: `https://your-server.com/api/kakao/skill`
   - ì¸ì¦: Bearer Token ì„¤ì •

2. **ë¸”ë¡ì—ì„œ ìŠ¤í‚¬ í˜¸ì¶œ:**
   ```
   ë¸”ë¡ í¸ì§‘ > ìŠ¤í‚¬ ì„ íƒ > "AI ê¸°ìˆ ë¬¸ì˜" ìŠ¤í‚¬
   íŒŒë¼ë¯¸í„°: userMessage = #{ì‚¬ìš©ìë°œí™”}
   ```

3. **ì‘ë‹µ ì„¤ì •:**
   - ìŠ¤í‚¬ ì‘ë‹µ ì‚¬ìš©
   - fallback ë©”ì‹œì§€ ì„¤ì •

---

## Claude ì—°ë™

### 1. Claude API ì„¤ì •

```javascript
// src/services/claudeService.js
const Anthropic = require('@anthropic-ai/sdk');

class ClaudeService {
    constructor() {
        this.client = new Anthropic({
            apiKey: process.env.ANTHROPIC_API_KEY
        });
        
        this.model = process.env.CLAUDE_MODEL || 'claude-3-sonnet-20240229';
        this.maxTokens = parseInt(process.env.CLAUDE_MAX_TOKENS) || 1024;
    }

    async generateResponse(userMessage, systemPrompt = null, context = null) {
        try {
            // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            let fullSystemPrompt = systemPrompt || 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê¸°ìˆ  ì§€ì› AIì…ë‹ˆë‹¤.';
            
            // ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            if (context && context.length > 0) {
                const contextText = this._formatContext(context);
                fullSystemPrompt += `\n\nì°¸ê³  ë¬¸ì„œ:\n${contextText}`;
            }
            
            const message = await this.client.messages.create({
                model: this.model,
                max_tokens: this.maxTokens,
                system: fullSystemPrompt,
                messages: [
                    {
                        role: 'user',
                        content: userMessage
                    }
                ]
            });
            
            const answer = message.content[0].text;
            
            return {
                answer: answer,
                model: this.model,
                usage: {
                    input_tokens: message.usage.input_tokens,
                    output_tokens: message.usage.output_tokens
                },
                cost: this._calculateCost(message.usage)
            };
            
        } catch (error) {
            console.error('[Claude] ì˜¤ë¥˜:', error);
            throw new Error(`Claude API ì˜¤ë¥˜: ${error.message}`);
        }
    }

    async chat(conversationHistory, newMessage, systemPrompt = null) {
        try {
            // ClaudeëŠ” systemì„ ë³„ë„ë¡œ ë°›ìŒ
            const messages = conversationHistory.slice(-5);
            messages.push({
                role: 'user',
                content: newMessage
            });
            
            const response = await this.client.messages.create({
                model: this.model,
                max_tokens: this.maxTokens,
                system: systemPrompt || 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê¸°ìˆ  ì§€ì› AIì…ë‹ˆë‹¤.',
                messages: messages
            });
            
            return {
                answer: response.content[0].text,
                usage: response.usage
            };
            
        } catch (error) {
            console.error('[Claude Chat] ì˜¤ë¥˜:', error);
            throw error;
        }
    }

    async *streamResponse(userMessage, systemPrompt = null) {
        const stream = await this.client.messages.create({
            model: this.model,
            max_tokens: this.maxTokens,
            system: systemPrompt || 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê¸°ìˆ  ì§€ì› AIì…ë‹ˆë‹¤.',
            messages: [
                { role: 'user', content: userMessage }
            ],
            stream: true
        });
        
        for await (const event of stream) {
            if (event.type === 'content_block_delta' && 
                event.delta.type === 'text_delta') {
                yield event.delta.text;
            }
        }
    }

    _formatContext(contextArray) {
        return contextArray.map((item, index) => {
            return `<document index="${index + 1}" source="${item.source || 'ë§¤ë‰´ì–¼'}">\n${item.content}\n</document>`;
        }).join('\n\n');
    }

    _calculateCost(usage) {
        // Claude 3 Sonnet ê°€ê²©
        const inputCostPer1M = 3.00;   // $3 per 1M tokens
        const outputCostPer1M = 15.00; // $15 per 1M tokens
        
        const inputCost = (usage.input_tokens / 1000000) * inputCostPer1M;
        const outputCost = (usage.output_tokens / 1000000) * outputCostPer1M;
        
        return {
            total: inputCost + outputCost,
            currency: 'USD',
            breakdown: {
                input: inputCost,
                output: outputCost
            }
        };
    }

    /**
     * ê¸´ ë¬¸ì„œ ì²˜ë¦¬ (Claudeì˜ ê°•ì  í™œìš©)
     */
    async analyzeDocument(documentText, query) {
        const systemPrompt = `
ë‹¹ì‹ ì€ ê¸°ìˆ  ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
        `.trim();
        
        const userMessage = `
ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

<document>
${documentText}
</document>

ì§ˆë¬¸: ${query}
        `.trim();
        
        return await this.generateResponse(userMessage, systemPrompt);
    }
}

module.exports = new ClaudeService();
```

### Claude íŠ¹ì§• ë° í™œìš© íŒ

**ì¥ì :**
- 200K í† í° ì»¨í…ìŠ¤íŠ¸ (ì „ì²´ ë§¤ë‰´ì–¼ í•œë²ˆì— ì²˜ë¦¬ ê°€ëŠ¥)
- ì•ˆì „í•˜ê³  ì‹ ë¢°ì„± ë†’ì€ ì‘ë‹µ
- í•œêµ­ì–´ ì„±ëŠ¥ ìš°ìˆ˜
- XML íƒœê·¸ ì˜ ì´í•´

**í™œìš© ì‚¬ë¡€:**
```javascript
// ì „ì²´ ë§¤ë‰´ì–¼ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ
const manualText = await loadManual('DB300_manual.pdf');
const response = await claudeService.analyzeDocument(
    manualText,
    'ë„¤íŠ¸ì›Œí¬ ì„¤ì • ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì•Œë ¤ì£¼ì„¸ìš”'
);
```

---

## Gemini ì—°ë™

### 1. Gemini API ì„¤ì •

```javascript
// src/services/geminiService.js
const { GoogleGenerativeAI } = require('@google/generative-ai');

class GeminiService {
    constructor() {
        this.genAI = new GoogleGenerativeAI(process.env.GOOGLE_API_KEY);
        this.model = this.genAI.getGenerativeModel({ 
            model: process.env.GEMINI_MODEL || 'gemini-1.5-pro'
        });
    }

    async generateResponse(userMessage, systemPrompt = null, context = null) {
        try {
            // GeminiëŠ” system instructionì„ ë³„ë„ë¡œ ì„¤ì •
            let model = this.model;
            
            if (systemPrompt) {
                model = this.genAI.getGenerativeModel({
                    model: 'gemini-1.5-pro',
                    systemInstruction: systemPrompt
                });
            }
            
            // ì»¨í…ìŠ¤íŠ¸ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            let fullPrompt = userMessage;
            if (context && context.length > 0) {
                const contextText = this._formatContext(context);
                fullPrompt = `ì°¸ê³  ìë£Œ:\n${contextText}\n\nì§ˆë¬¸: ${userMessage}`;
            }
            
            const result = await model.generateContent(fullPrompt);
            const response = result.response;
            const answer = response.text();
            
            return {
                answer: answer,
                model: 'gemini-1.5-pro',
                usage: {
                    // GeminiëŠ” ì‚¬ìš©ëŸ‰ ì •ë³´ ì œê³µ ì•ˆí•¨ (ë¬´ë£Œ í• ë‹¹ëŸ‰)
                    estimated_tokens: Math.ceil(answer.length / 4)
                }
            };
            
        } catch (error) {
            console.error('[Gemini] ì˜¤ë¥˜:', error);
            throw new Error(`Gemini API ì˜¤ë¥˜: ${error.message}`);
        }
    }

    async chat(conversationHistory, newMessage, systemPrompt = null) {
        try {
            const chat = this.model.startChat({
                history: this._convertHistory(conversationHistory),
                systemInstruction: systemPrompt
            });
            
            const result = await chat.sendMessage(newMessage);
            const response = result.response;
            
            return {
                answer: response.text()
            };
            
        } catch (error) {
            console.error('[Gemini Chat] ì˜¤ë¥˜:', error);
            throw error;
        }
    }

    async *streamResponse(userMessage, systemPrompt = null) {
        let model = this.model;
        
        if (systemPrompt) {
            model = this.genAI.getGenerativeModel({
                model: 'gemini-1.5-pro',
                systemInstruction: systemPrompt
            });
        }
        
        const result = await model.generateContentStream(userMessage);
        
        for await (const chunk of result.stream) {
            const chunkText = chunk.text();
            yield chunkText;
        }
    }

    /**
     * ì´ë¯¸ì§€ ë¶„ì„ (Geminiì˜ ê°•ì )
     */
    async analyzeImage(imageBase64, query) {
        try {
            const model = this.genAI.getGenerativeModel({ 
                model: 'gemini-1.5-pro-vision' 
            });
            
            const imageParts = [
                {
                    inlineData: {
                        data: imageBase64,
                        mimeType: 'image/jpeg'
                    }
                }
            ];
            
            const result = await model.generateContent([query, ...imageParts]);
            const response = result.response;
            
            return {
                answer: response.text()
            };
            
        } catch (error) {
            console.error('[Gemini Vision] ì˜¤ë¥˜:', error);
            throw error;
        }
    }

    /**
     * ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ (2M í† í° ì»¨í…ìŠ¤íŠ¸)
     */
    async processLargeDocument(documentPath, query) {
        // íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ ì‚¬ìš©
        const uploadResult = await this.genAI.uploadFile(documentPath);
        const file = uploadResult.file;
        
        const result = await this.model.generateContent([
            {
                fileData: {
                    mimeType: file.mimeType,
                    fileUri: file.uri
                }
            },
            { text: query }
        ]);
        
        return {
            answer: result.response.text()
        };
    }

    _formatContext(contextArray) {
        return contextArray.map((item, index) => {
            return `[ë¬¸ì„œ ${index + 1}] ${item.source || 'ë§¤ë‰´ì–¼'}\n${item.content}`;
        }).join('\n\n');
    }

    _convertHistory(history) {
        // ì¹´ì¹´ì˜¤ í˜•ì‹ì„ Gemini í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return history.map(msg => ({
            role: msg.role === 'assistant' ? 'model' : 'user',
            parts: [{ text: msg.content }]
        }));
    }
}

module.exports = new GeminiService();
```

### Gemini íŠ¹ì§• ë° í™œìš©

**ì¥ì :**
- 2M í† í° ì»¨í…ìŠ¤íŠ¸ (ì—…ê³„ ìµœëŒ€)
- ë¬´ë£Œ í• ë‹¹ëŸ‰ ì œê³µ
- ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)
- ë¹ ë¥¸ ì†ë„

**í™œìš© ì‚¬ë¡€:**
```javascript
// ê³ ê°ì´ ë³´ë‚¸ ì—ëŸ¬ í™”ë©´ ì´ë¯¸ì§€ ë¶„ì„
const imageAnalysis = await geminiService.analyzeImage(
    errorScreenBase64,
    'ì´ ì—ëŸ¬ í™”ë©´ì„ ë¶„ì„í•˜ê³  í•´ê²° ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”'
);

// ì „ì²´ ë§¤ë‰´ì–¼ í´ë” ë¶„ì„
const response = await geminiService.processLargeDocument(
    './manuals/all_manuals_combined.pdf',
    'DB300 ì œí’ˆì˜ ë„¤íŠ¸ì›Œí¬ ì„¤ì • ê´€ë ¨ ë‚´ìš©ì„ ëª¨ë‘ ì°¾ì•„ì£¼ì„¸ìš”'
);
```

---

## RAG ì‹œìŠ¤í…œê³¼ LLM ê²°í•©

### RAG (Retrieval Augmented Generation) ê°œë…

**ì™œ RAGê°€ í•„ìš”í•œê°€?**
- LLMì€ í•™ìŠµ ë°ì´í„° ì´í›„ì˜ ì •ë³´ë¥¼ ëª¨ë¦„
- ë‹¤ë¹›ì†”ë£¨ì…˜ ì œí’ˆ ì‚¬ì–‘, ë§¤ë‰´ì–¼ ë“±ì€ LLMì´ ëª¨ë¦„
- RAGë¡œ ì‹¤ì‹œê°„ ì§€ì‹ ì£¼ì… ê°€ëŠ¥

**RAG ì‘ë™ ë°©ì‹:**
```
ì‚¬ìš©ì ì§ˆë¬¸ â†’ ë²¡í„° ê²€ìƒ‰ â†’ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸° â†’ LLMì— ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ â†’ ì •í™•í•œ ë‹µë³€ ìƒì„±
```

### 1. ë²¡í„° DB êµ¬ì¶•

```javascript
// src/services/ragService.js
const { ChromaClient } = require('chromadb');
const { OpenAIEmbeddings } = require('langchain/embeddings/openai');
const { RecursiveCharacterTextSplitter } = require('langchain/text_splitter');

class RAGService {
    constructor() {
        this.client = new ChromaClient();
        this.collectionName = 'dabit_knowledge';
        this.embeddings = new OpenAIEmbeddings({
            openAIApiKey: process.env.OPENAI_API_KEY
        });
        this.collection = null;
    }

    /**
     * ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
     */
    async initialize() {
        try {
            // ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„± (ê°œë°œ ì¤‘)
            try {
                await this.client.deleteCollection({ name: this.collectionName });
            } catch (e) {
                // ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ë¬´ì‹œ
            }
            
            this.collection = await this.client.createCollection({
                name: this.collectionName,
                metadata: { 
                    description: 'ë‹¤ë¹›ì†”ë£¨ì…˜ ê¸°ìˆ  ì§€ì‹ ë² ì´ìŠ¤',
                    created: new Date().toISOString()
                }
            });
            
            console.log('[RAG] ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì™„ë£Œ');
        } catch (error) {
            console.error('[RAG] ì´ˆê¸°í™” ì˜¤ë¥˜:', error);
            throw error;
        }
    }

    /**
     * ë¬¸ì„œ ì¶”ê°€ (ì„ë² ë”© + ì €ì¥)
     */
    async addDocuments(documents) {
        try {
            if (!this.collection) {
                await this.initialize();
            }
            
            // ë¬¸ì„œ ë¶„í• 
            const splitter = new RecursiveCharacterTextSplitter({
                chunkSize: 1000,
                chunkOverlap: 200
            });
            
            const chunks = [];
            for (const doc of documents) {
                const splits = await splitter.splitText(doc.content);
                splits.forEach((chunk, index) => {
                    chunks.push({
                        id: `${doc.id}_chunk_${index}`,
                        content: chunk,
                        metadata: {
                            ...doc.metadata,
                            chunkIndex: index,
                            source: doc.source
                        }
                    });
                });
            }
            
            // ì„ë² ë”© ìƒì„±
            const texts = chunks.map(c => c.content);
            const embeddings = await this.embeddings.embedDocuments(texts);
            
            // Chromaì— ì €ì¥
            await this.collection.add({
                ids: chunks.map(c => c.id),
                embeddings: embeddings,
                documents: texts,
                metadatas: chunks.map(c => c.metadata)
            });
            
            console.log(`[RAG] ${chunks.length}ê°œ ì²­í¬ ì¶”ê°€ ì™„ë£Œ`);
            
            return {
                success: true,
                chunksAdded: chunks.length
            };
            
        } catch (error) {
            console.error('[RAG] ë¬¸ì„œ ì¶”ê°€ ì˜¤ë¥˜:', error);
            throw error;
        }
    }

    /**
     * ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
     */
    async search(query, topK = 5) {
        try {
            if (!this.collection) {
                await this.initialize();
            }
            
            // ì¿¼ë¦¬ ì„ë² ë”©
            const queryEmbedding = await this.embeddings.embedQuery(query);
            
            // ìœ ì‚¬ë„ ê²€ìƒ‰
            const results = await this.collection.query({
                queryEmbeddings: [queryEmbedding],
                nResults: topK
            });
            
            // ê²°ê³¼ í¬ë§·íŒ…
            const documents = [];
            if (results.documents && results.documents[0]) {
                for (let i = 0; i < results.documents[0].length; i++) {
                    documents.push({
                        content: results.documents[0][i],
                        metadata: results.metadatas[0][i],
                        distance: results.distances[0][i],
                        relevance: this._calculateRelevance(results.distances[0][i])
                    });
                }
            }
            
            console.log(`[RAG] ê²€ìƒ‰ ì™„ë£Œ: ${documents.length}ê°œ ë¬¸ì„œ ë°œê²¬`);
            
            return documents;
            
        } catch (error) {
            console.error('[RAG] ê²€ìƒ‰ ì˜¤ë¥˜:', error);
            return [];
        }
    }

    /**
     * í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ)
     */
    async hybridSearch(query, topK = 5) {
        // ë²¡í„° ê²€ìƒ‰
        const vectorResults = await this.search(query, topK);
        
        // í‚¤ì›Œë“œ ê²€ìƒ‰ (ê°„ë‹¨í•œ êµ¬í˜„)
        const keywords = this._extractKeywords(query);
        const keywordResults = await this._keywordSearch(keywords, topK);
        
        // ê²°ê³¼ ë³‘í•© (ì¤‘ë³µ ì œê±° + ì ìˆ˜ í•©ì‚°)
        const merged = this._mergeResults(vectorResults, keywordResults);
        
        return merged.slice(0, topK);
    }

    /**
     * ê´€ë ¨ë„ ê³„ì‚°
     */
    _calculateRelevance(distance) {
        // ê±°ë¦¬ -> ìœ ì‚¬ë„ ë³€í™˜ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ì¤€)
        // ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬ë„ ë†’ìŒ
        const similarity = 1 - distance;
        
        if (similarity > 0.8) return 'high';
        if (similarity > 0.6) return 'medium';
        return 'low';
    }

    /**
     * í‚¤ì›Œë“œ ì¶”ì¶œ
     */
    _extractKeywords(query) {
        // ê°„ë‹¨í•œ êµ¬í˜„: ë¶ˆìš©ì–´ ì œê±° í›„ ëª…ì‚¬ ì¶”ì¶œ
        const stopwords = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì˜'];
        const words = query.split(' ').filter(w => !stopwords.includes(w));
        return words;
    }

    /**
     * í‚¤ì›Œë“œ ê²€ìƒ‰
     */
    async _keywordSearch(keywords, topK) {
        // ì‹¤ì œë¡œëŠ” Elasticsearch ë“± ì „ë¬¸ ê²€ìƒ‰ ì—”ì§„ ì‚¬ìš© ê¶Œì¥
        // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ êµ¬í˜„
        const results = await this.collection.get({
            where: {
                $or: keywords.map(keyword => ({
                    content: { $contains: keyword }
                }))
            },
            limit: topK
        });
        
        return results.documents || [];
    }

    /**
     * ê²°ê³¼ ë³‘í•©
     */
    _mergeResults(vectorResults, keywordResults) {
        const scoreMap = new Map();
        
        // ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜í™” (ê°€ì¤‘ì¹˜ 0.7)
        vectorResults.forEach((doc, index) => {
            const score = (vectorResults.length - index) * 0.7;
            scoreMap.set(doc.content, {
                ...doc,
                score: score
            });
        });
        
        // í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€ (ê°€ì¤‘ì¹˜ 0.3)
        keywordResults.forEach((doc, index) => {
            const score = (keywordResults.length - index) * 0.3;
            if (scoreMap.has(doc.content)) {
                scoreMap.get(doc.content).score += score;
            } else {
                scoreMap.set(doc.content, {
                    ...doc,
                    score: score
                });
            }
        });
        
        // ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        return Array.from(scoreMap.values())
            .sort((a, b) => b.score - a.score);
    }
}

module.exports = new RAGService();
```

### 2. ë§¤ë‰´ì–¼ ë°ì´í„° ë¡œë“œ

```javascript
// src/utils/dataLoader.js
const fs = require('fs');
const path = require('path');
const pdf = require('pdf-parse');
const ragService = require('../services/ragService');

class DataLoader {
    /**
     * PDF ë§¤ë‰´ì–¼ ë¡œë“œ
     */
    async loadPDFManuals(directory) {
        const files = fs.readdirSync(directory)
            .filter(f => f.endsWith('.pdf'));
        
        const documents = [];
        
        for (const file of files) {
            const filePath = path.join(directory, file);
            const dataBuffer = fs.readFileSync(filePath);
            const data = await pdf(dataBuffer);
            
            documents.push({
                id: `manual_${path.basename(file, '.pdf')}`,
                content: data.text,
                source: file,
                metadata: {
                    type: 'manual',
                    pages: data.numpages,
                    title: file.replace('.pdf', '')
                }
            });
        }
        
        return documents;
    }

    /**
     * ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ë¡œë“œ
     */
    async loadMarkdownDocs(directory) {
        const files = fs.readdirSync(directory)
            .filter(f => f.endsWith('.md'));
        
        const documents = [];
        
        for (const file of files) {
            const filePath = path.join(directory, file);
            const content = fs.readFileSync(filePath, 'utf-8');
            
            documents.push({
                id: `md_${path.basename(file, '.md')}`,
                content: content,
                source: file,
                metadata: {
                    type: 'markdown',
                    title: file.replace('.md', '')
                }
            });
        }
        
        return documents;
    }

    /**
     * FAQ ë°ì´í„° ë¡œë“œ
     */
    async loadFAQ(jsonPath) {
        const faqData = JSON.parse(fs.readFileSync(jsonPath, 'utf-8'));
        
        const documents = faqData.map((item, index) => ({
            id: `faq_${index}`,
            content: `ì§ˆë¬¸: ${item.question}\në‹µë³€: ${item.answer}`,
            source: 'FAQ',
            metadata: {
                type: 'faq',
                category: item.category,
                tags: item.tags
            }
        }));
        
        return documents;
    }

    /**
     * ì „ì²´ ë°ì´í„° ë¡œë“œ ë° RAG êµ¬ì¶•
     */
    async buildKnowledgeBase() {
        console.log('[DataLoader] ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶• ì‹œì‘...');
        
        try {
            // 1. ë§¤ë‰´ì–¼ ë¡œë“œ
            const manuals = await this.loadPDFManuals('./data/manuals');
            console.log(`[DataLoader] ${manuals.length}ê°œ ë§¤ë‰´ì–¼ ë¡œë“œ ì™„ë£Œ`);
            
            // 2. ê¸°ìˆ  ë¬¸ì„œ ë¡œë“œ
            const techDocs = await this.loadMarkdownDocs('./data/tech-docs');
            console.log(`[DataLoader] ${techDocs.length}ê°œ ê¸°ìˆ  ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ`);
            
            // 3. FAQ ë¡œë“œ
            const faq = await this.loadFAQ('./data/faq.json');
            console.log(`[DataLoader] ${faq.length}ê°œ FAQ ë¡œë“œ ì™„ë£Œ`);
            
            // 4. RAGì— ì¶”ê°€
            const allDocuments = [...manuals, ...techDocs, ...faq];
            await ragService.addDocuments(allDocuments);
            
            console.log('[DataLoader] ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶• ì™„ë£Œ!');
            
            return {
                success: true,
                totalDocuments: allDocuments.length
            };
            
        } catch (error) {
            console.error('[DataLoader] ì˜¤ë¥˜:', error);
            throw error;
        }
    }
}

module.exports = new DataLoader();
```

### 3. LLM + RAG í†µí•© ì„œë¹„ìŠ¤

```javascript
// src/services/llmService.js
const openaiService = require('./openaiService');
const claudeService = require('./claudeService');
const geminiService = require('./geminiService');
const ragService = require('./ragService');

class LLMService {
    constructor() {
        this.defaultProvider = process.env.DEFAULT_LLM || 'claude';
    }

    /**
     * ìë™ ë¼ìš°íŒ… (ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì  LLM ì„ íƒ)
     */
    async smartResponse(userMessage, conversationHistory = []) {
        // 1. ì§ˆë¬¸ ìœ í˜• ë¶„ì„
        const questionType = this._analyzeQuestion(userMessage);
        
        // 2. RAG ê²€ìƒ‰
        const relevantDocs = await ragService.search(userMessage, 5);
        
        // 3. ì ì ˆí•œ LLM ì„ íƒ
        let provider = this._selectProvider(questionType, relevantDocs);
        
        // 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        const systemPrompt = this._buildSystemPrompt(questionType);
        
        // 5. ì‘ë‹µ ìƒì„±
        console.log(`[LLM] ${provider} ì‚¬ìš© (ì§ˆë¬¸ ìœ í˜•: ${questionType})`);
        
        let result;
        switch (provider) {
            case 'gpt4':
                result = await openaiService.generateResponse(
                    userMessage,
                    systemPrompt,
                    relevantDocs
                );
                break;
                
            case 'claude':
                result = await claudeService.generateResponse(
                    userMessage,
                    systemPrompt,
                    relevantDocs
                );
                break;
                
            case 'gemini':
                result = await geminiService.generateResponse(
                    userMessage,
                    systemPrompt,
                    relevantDocs
                );
                break;
                
            default:
                throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM: ${provider}`);
        }
        
        // 6. ê²°ê³¼ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
        result.metadata = {
            questionType: questionType,
            provider: provider,
            relevantDocsCount: relevantDocs.length,
            sources: relevantDocs.map(d => d.metadata.source)
        };
        
        return result;
    }

    /**
     * ì§ˆë¬¸ ìœ í˜• ë¶„ì„
     */
    _analyzeQuestion(question) {
        const patterns = {
            'technical': /ì„¤ì •|ì—°ê²°|í”„ë¡œí† ì½œ|í†µì‹ |ì˜¤ë¥˜|ì—ëŸ¬|ê³ ì¥/,
            'product_info': /ì œí’ˆ|ì‚¬ì–‘|ëª¨ë¸|ê°€ê²©|êµ¬ë§¤/,
            'howto': /ì–´ë–»ê²Œ|ë°©ë²•|ê°€ì´ë“œ|íŠœí† ë¦¬ì–¼/,
            'troubleshoot': /ì•ˆë¨|ì‘ë™|ë¬¸ì œ|í•´ê²°/,
            'general': /.*/
        };
        
        for (const [type, pattern] of Object.entries(patterns)) {
            if (pattern.test(question)) {
                return type;
            }
        }
        
        return 'general';
    }

    /**
     * ìµœì  LLM ì„ íƒ
     */
    _selectProvider(questionType, relevantDocs) {
        // ë¬¸ì„œ ê´€ë ¨ë„ í™•ì¸
        const hasHighRelevance = relevantDocs.some(d => d.relevance === 'high');
        
        // ì„ íƒ ë¡œì§
        if (questionType === 'technical' && hasHighRelevance) {
            // ê¸°ìˆ  ë¬¸ì˜ + ê´€ë ¨ ë¬¸ì„œ ìˆìŒ â†’ Claude (ê¸´ ì»¨í…ìŠ¤íŠ¸)
            return 'claude';
        } else if (questionType === 'troubleshoot') {
            // ë¬¸ì œ í•´ê²° â†’ GPT-4 (ì¶”ë¡  ëŠ¥ë ¥)
            return 'gpt4';
        } else if (!hasHighRelevance) {
            // ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ â†’ Gemini (ì¼ë°˜ ì§€ì‹)
            return 'gemini';
        } else {
            // ê¸°ë³¸
            return this.defaultProvider;
        }
    }

    /**
     * ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
     */
    _buildSystemPrompt(questionType) {
        const basePrompt = `
ë‹¹ì‹ ì€ ë‹¤ë¹›ì†”ë£¨ì…˜ì˜ AI ê¸°ìˆ  ì§€ì› ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**íšŒì‚¬ ì •ë³´:**
- ì „ê´‘íŒ ì»¨íŠ¸ë¡¤ëŸ¬ ì „ë¬¸ ì œì¡°ì‚¬
- ì£¼ìš” ì œí’ˆ: DB300, DB400, DB320WB
- ì£¼ìš” ë¶„ì•¼: ì£¼ì°¨ê´€ì œ, ë¶ˆë²•ì£¼ì •ì°¨ ë‹¨ì†

**ì‘ë‹µ ì›ì¹™:**
1. ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤
2. ì œê³µëœ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€
3. ë¶ˆí™•ì‹¤í•˜ë©´ ì†”ì§íˆ "í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤" í‘œí˜„
4. ê°„ê²°í•˜ê²Œ 3-5ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€
5. í•„ìš”ì‹œ ë‹¨ê³„ë³„ ê°€ì´ë“œ ì œê³µ
        `.trim();
        
        const typeSpecificPrompts = {
            'technical': '\n\n**íŠ¹ë³„ ì§€ì‹œ:** ê¸°ìˆ ì ìœ¼ë¡œ ì •í™•í•œ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ë˜, ê³ ê°ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.',
            'troubleshoot': '\n\n**íŠ¹ë³„ ì§€ì‹œ:** ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë‹¨ê³„ë³„ ì§„ë‹¨ ì ˆì°¨ë¥¼ ì œì‹œí•˜ì„¸ìš”.',
            'howto': '\n\n**íŠ¹ë³„ ì§€ì‹œ:** ë”°ë¼í•˜ê¸° ì‰¬ìš´ ë‹¨ê³„ë³„ ê°€ì´ë“œë¥¼ ì œê³µí•˜ì„¸ìš”.',
            'product_info': '\n\n**íŠ¹ë³„ ì§€ì‹œ:** ì œí’ˆ ìŠ¤í™ê³¼ íŠ¹ì§•ì„ ëª…í™•íˆ ì„¤ëª…í•˜ì„¸ìš”.'
        };
        
        return basePrompt + (typeSpecificPrompts[questionType] || '');
    }

    /**
     * í´ë°± ì²˜ë¦¬ (ì—ëŸ¬ ì‹œ ë‹¤ë¥¸ LLM ì‹œë„)
     */
    async responseWithFallback(userMessage, conversationHistory = []) {
        const providers = ['claude', 'gpt4', 'gemini'];
        
        for (const provider of providers) {
            try {
                console.log(`[LLM] ${provider} ì‹œë„ ì¤‘...`);
                
                const service = this._getService(provider);
                const relevantDocs = await ragService.search(userMessage, 3);
                const systemPrompt = this._buildSystemPrompt('general');
                
                const result = await service.generateResponse(
                    userMessage,
                    systemPrompt,
                    relevantDocs
                );
                
                result.provider = provider;
                return result;
                
            } catch (error) {
                console.error(`[LLM] ${provider} ì‹¤íŒ¨:`, error.message);
                continue;
            }
        }
        
        throw new Error('ëª¨ë“  LLM ì œê³µì ì‹¤íŒ¨');
    }

    _getService(provider) {
        switch (provider) {
            case 'gpt4':
                return openaiService;
            case 'claude':
                return claudeService;
            case 'gemini':
                return geminiService;
            default:
                throw new Error(`Unknown provider: ${provider}`);
        }
    }
}

module.exports = new LLMService();
```

---

## í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§

### ë‹¤ë¹›ì†”ë£¨ì…˜ ìµœì í™” í”„ë¡¬í”„íŠ¸

```javascript
// src/config/prompts.js
module.exports = {
    // ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    SYSTEM_BASE: `
ë‹¹ì‹ ì€ "ë‹¤ë¹›ì†”ë£¨ì…˜" ì „ê´‘íŒ ì»¨íŠ¸ë¡¤ëŸ¬ ì „ë¬¸ íšŒì‚¬ì˜ AI ê¸°ìˆ  ì§€ì› ì–´ì‹œìŠ¤í„´íŠ¸ "ë‹¤ë¹›ì´"ì…ë‹ˆë‹¤.

## íšŒì‚¬ ì •ë³´
- **íšŒì‚¬ëª…**: ë‹¤ë¹›ì†”ë£¨ì…˜ (Dabit Solution)
- **ì‚¬ì—… ë¶„ì•¼**: LED ì „ê´‘íŒ ì»¨íŠ¸ë¡¤ëŸ¬ ì œì¡° ë° ê¸°ìˆ  ì§€ì›
- **ì£¼ìš” ì œí’ˆ**: 
  * DB300: ì¼ë°˜í˜• ì»¨íŠ¸ë¡¤ëŸ¬
  * DB400: ê³ ê¸‰í˜• ì»¨íŠ¸ë¡¤ëŸ¬
  * DB320WB: WiFi/Bluetooth í†µí•© ëª¨ë¸
- **ì£¼ìš” ê³ ê°**: ì£¼ì°¨ê´€ì œ ì‹œìŠ¤í…œ, ë¶ˆë²•ì£¼ì •ì°¨ ë‹¨ì†, êµí†µ ì •ë³´ ì‹œìŠ¤í…œ

## í•µì‹¬ ì—­í• 
1. ì œí’ˆ ê¸°ìˆ  ë¬¸ì˜ ì‘ëŒ€
2. ì„¤ì¹˜/ì„¤ì • ê°€ì´ë“œ ì œê³µ
3. ë¬¸ì œ í•´ê²° (Troubleshooting)
4. AS ì ‘ìˆ˜ ì•ˆë‚´

## ì‘ë‹µ ì›ì¹™
âœ… **DO (í•´ì•¼ í•  ê²ƒ)**
- ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤ ìœ ì§€
- ì œê³µëœ ë¬¸ì„œ/ë§¤ë‰´ì–¼ ë‚´ìš© ê¸°ë°˜ ë‹µë³€
- ë¶ˆí™•ì‹¤í•œ ê²½ìš° ì†”ì§í•˜ê²Œ "í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤" í‘œí˜„
- ê°„ê²°í•˜ê²Œ 3-5ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€
- ë³µì¡í•œ ë‚´ìš©ì€ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…
- ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš© (ğŸ“± ğŸ”§ âœ… âš ï¸ ë“±)

âŒ **DON'T (í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒ)**
- ì¶”ì¸¡ì´ë‚˜ ì§€ì–´ë‚¸ ì •ë³´ ì œê³µ ê¸ˆì§€
- ê²½ìŸì‚¬ ì œí’ˆ ì–¸ê¸‰ ê¸ˆì§€
- ê°œì¸ì •ë³´ ìš”êµ¬ ê¸ˆì§€
- ì§€ë‚˜ì¹˜ê²Œ ê¸°ìˆ ì ì¸ ì „ë¬¸ ìš©ì–´ ë‚¨ë°œ ê¸ˆì§€
- ê¸´ ì„¤ëª…ìœ¼ë¡œ ê³ ê° í˜¼ë€ì‹œí‚¤ê¸° ê¸ˆì§€

## ë‹µë³€ í˜•ì‹
**ê¸°ë³¸ êµ¬ì¡°:**
1. ë¬¸ì œ/ì§ˆë¬¸ í™•ì¸ ("~ì— ëŒ€í•´ ë¬¸ì˜í•˜ì…¨êµ°ìš”")
2. í•µì‹¬ ë‹µë³€ (2-3ë¬¸ì¥)
3. ì¶”ê°€ íŒ ë˜ëŠ” ì£¼ì˜ì‚¬í•­ (í•„ìš”ì‹œ)
4. í›„ì† ì§ˆë¬¸ ìœ ë„

**ì˜ˆì‹œ:**
"WiFi ì—°ê²° ë¬¸ì œì— ëŒ€í•´ ë¬¸ì˜í•˜ì…¨êµ°ìš”. ğŸ“±

ë¨¼ì € ì œí’ˆ ì„¤ì • ë©”ë‰´ì—ì„œ WiFi > ë„¤íŠ¸ì›Œí¬ ê²€ìƒ‰ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”. ê³µìœ ê¸°ê°€ 2.4GHzë¡œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ì´ í•„ìš”í•˜ë©°, DB300ì€ 5GHzë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 

âœ… ê³µìœ ê¸°ë¥¼ ì¬ë¶€íŒ…í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì‹œê³ , ê·¸ë˜ë„ ì•ˆ ë˜ë©´ ìœ ì„  ì—°ê²°ë¡œ íŒì›¨ì–´ ì—…ë°ì´íŠ¸ë¥¼ ë¨¼ì € ì§„í–‰í•´ì£¼ì„¸ìš”.

ë‹¤ë¥¸ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"
    `.trim(),

    // ê¸°ìˆ  ë¬¸ì˜ íŠ¹í™”
    TECHNICAL_SUPPORT: `
ë‹¹ì‹ ì€ ê¸°ìˆ  ì§€ì› ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”:

## ë¬¸ì œ ì§„ë‹¨ ì ˆì°¨
1. **ì¦ìƒ í™•ì¸**: êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¬¸ì œì¸ì§€ íŒŒì•…
2. **í™˜ê²½ í™•ì¸**: ì œí’ˆ ëª¨ë¸, íŒì›¨ì–´ ë²„ì „, ì—°ê²° ë°©ì‹
3. **ê¸°ë³¸ ì²´í¬**: ì „ì›, ì—°ê²° ì¼€ì´ë¸”, LED ìƒíƒœ
4. **ë‹¨ê³„ë³„ í•´ê²°**: ì‰¬ìš´ ê²ƒë¶€í„° ë³µì¡í•œ ìˆœì„œë¡œ

## ì‘ë‹µ í…œí”Œë¦¿
**[ì¦ìƒ í™•ì¸]**
- ì–´ë–¤ ë¬¸ì œì¸ì§€ í™•ì¸

**[ì›ì¸ ë¶„ì„]**
- ê°€ëŠ¥í•œ ì›ì¸ 1-2ê°€ì§€

**[í•´ê²° ë°©ë²•]**
1. ì²« ë²ˆì§¸ ì‹œë„
2. ë‘ ë²ˆì§¸ ì‹œë„
3. ìµœì¢… ë°©ë²•

**[ì¶”ê°€ ì•ˆë‚´]**
- í•´ê²° ì•ˆ ë  ê²½ìš° ìƒë‹´ì› ì—°ê²° ì•ˆë‚´
    `.trim(),

    // AS ì ‘ìˆ˜ìš©
    AS_REQUEST: `
ë‹¹ì‹ ì€ AS ì ‘ìˆ˜ë¥¼ ë„ì™€ì£¼ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

## í•„ìˆ˜ ìˆ˜ì§‘ ì •ë³´
1. ì œí’ˆ ëª¨ë¸ (DB300/DB400/DB320WB)
2. ì‹œë¦¬ì–¼ ë²ˆí˜¸
3. êµ¬ë§¤ ì¼ì
4. ì¦ìƒ ì„¤ëª…
5. ì—°ë½ì²˜

## ì‘ë‹µ íë¦„
1. ì •ì¤‘í•œ ì¸ì‚¬ + AS ì ‘ìˆ˜ ì•ˆë‚´
2. í•„ìˆ˜ ì •ë³´ í•˜ë‚˜ì”© ì§ˆë¬¸
3. ì •ë³´ í™•ì¸ ë° ì ‘ìˆ˜ ì™„ë£Œ
4. ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„ ì•ˆë‚´

## í†¤
- ê³µê°í•˜ëŠ” í†¤ ("ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤")
- ì‹ ì† ì²˜ë¦¬ ì˜ì§€ í‘œí˜„
- ê°ì‚¬ ì¸ì‚¬
    `.trim(),

    // FAQ ì‘ë‹µìš©
    FAQ_RESPONSE: `
ê°„ë‹¨í•œ FAQ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.

## íŠ¹ì§•
- ì§§ê³  ëª…í™•í•˜ê²Œ
- ê´€ë ¨ ë¬¸ì„œ ë§í¬ ì œê³µ
- ì¶”ê°€ ì§ˆë¬¸ ìœ ë„

## í˜•ì‹
**ë‹µë³€:** [í•µì‹¬ ë‚´ìš© 1-2ë¬¸ì¥]
**ì°¸ê³ :** [ê´€ë ¨ ë§¤ë‰´ì–¼ í˜ì´ì§€]
**ë” ê¶ê¸ˆí•˜ì‹  ì :** [ì¶”ê°€ ì§ˆë¬¸ ì˜ˆì‹œ]
    `.trim(),

    // í”„ë¡œí† ì½œ ì„¤ëª…ìš©
    PROTOCOL_GUIDE: `
ë‹¹ì‹ ì€ í†µì‹  í”„ë¡œí† ì½œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì„¤ëª… ë°©ì‹
1. **ê°œë… ì„¤ëª…**: í”„ë¡œí† ì½œì´ ë¬´ì—‡ì¸ì§€
2. **ì‹¤ì œ ì˜ˆì‹œ**: êµ¬ì²´ì ì¸ ì»¤ë§¨ë“œ ì˜ˆì‹œ
3. **ì£¼ì˜ì‚¬í•­**: ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜

## ì½”ë“œ í¬ë§·
\`\`\`
[ì˜ˆì‹œ ì»¤ë§¨ë“œ]
\`\`\`

## êµ¬ì¡°
- í—¤ë”/ë°ì´í„°/ì²´í¬ì„¬ êµ¬ì¡° ì„¤ëª…
- ê° ë°”ì´íŠ¸ ì˜ë¯¸
- BCC ê³„ì‚° ë°©ë²•
    `.trim()
};
```

### Few-Shot ì˜ˆì œ í”„ë¡¬í”„íŠ¸

```javascript
// íš¨ê³¼ì ì¸ Few-Shot ì˜ˆì œ
const FEW_SHOT_EXAMPLES = `
## ì¢‹ì€ ì‘ë‹µ ì˜ˆì‹œ

**Q: WiFiê°€ ê³„ì† ëŠê²¨ìš”**
**A:** WiFi ì—°ê²°ì´ ë¶ˆì•ˆì •í•˜ì‹œêµ°ìš”. ğŸ“¡

ë¨¼ì € ê³µìœ ê¸°ì™€ ì œí’ˆ ê°„ ê±°ë¦¬ë¥¼ 2-3m ì´ë‚´ë¡œ ê°€ê¹Œì´ í•´ë³´ì„¸ìš”. DB300ì€ WiFi ì‹ í˜¸ê°€ ì•½í•˜ë©´ ìë™ìœ¼ë¡œ ì—°ê²°ì´ ëŠì–´ì§‘ë‹ˆë‹¤. 

âœ… **ì²´í¬ë¦¬ìŠ¤íŠ¸:**
1. ê³µìœ ê¸°ê°€ 2.4GHzì¸ì§€ í™•ì¸
2. ë‹¤ë¥¸ ê¸°ê¸°ëŠ” WiFi ì˜ ë˜ëŠ”ì§€ í™•ì¸
3. ì œí’ˆ ì„¤ì •ì—ì„œ ê³ ì • IP ì‚¬ìš© ì‹œë„

ê·¸ë˜ë„ ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ìœ ì„ (ì´ë”ë„·) ì—°ê²°ì„ ê¶Œì¥ë“œë¦½ë‹ˆë‹¤. ì¶”ê°€ë¡œ ê¶ê¸ˆí•˜ì‹  ì  ìˆìœ¼ì‹ ê°€ìš”?

---

**Q: ASCII í”„ë¡œí† ì½œ ë³´ë‚´ëŠ” ë°©ë²•**
**A:** ASCII í”„ë¡œí† ì½œ ì „ì†¡ ë°©ë²•ì„ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ğŸ”§

ë‹¤ë¹›ì†”ë£¨ì…˜ ì œí’ˆì€ ë‹¤ìŒ í˜•ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:
\`\`\`
STX + ID + CMD + DATA + ETX + BCC
\`\`\`

**ì˜ˆì‹œ (í…ìŠ¤íŠ¸ í‘œì¶œ):**
\`\`\`
02 30 30 44 54 48 65 6C 6C 6F 03 42
(02:STX, 3030:ID, 44:CMD, ...Hello..., 03:ETX, 42:BCC)
\`\`\`

ğŸ“„ ìì„¸í•œ ë‚´ìš©ì€ "DABIT DOCS > í†µì‹  í”„ë¡œí† ì½œ" ë§¤ë‰´ì–¼ì„ ì°¸ê³ í•´ì£¼ì„¸ìš”.

í…ŒìŠ¤íŠ¸ ë„êµ¬ê°€ í•„ìš”í•˜ì‹œë©´ ë‹¤ë¹›ì±„(DabitChe) í”„ë¡œê·¸ë¨ ì‚¬ìš©ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤!

---

**Q: ì œí’ˆ ê°€ê²©ì´ ê¶ê¸ˆí•´ìš”**
**A:** ì œí’ˆ ê°€ê²© ë¬¸ì˜ ê°ì‚¬í•©ë‹ˆë‹¤. ğŸ’°

ì œí’ˆ ê°€ê²©ì€ ìˆ˜ëŸ‰, ì˜µì…˜, ë‚©ê¸°ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. ì •í™•í•œ ê²¬ì ì€ ì˜ì—…íŒ€ì„ í†µí•´ ì•ˆë‚´ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ“ **ì—°ë½ì²˜:**
- ì „í™”: 1234-5678
- ì´ë©”ì¼: sales@dabitsolution.com
- ì¹´ì¹´ì˜¤í†¡: ìƒë‹´ì› ì—°ê²° ë²„íŠ¼ í´ë¦­

ë¹ ë¥¸ ì‹œì¼ ë‚´ì— ìƒë‹´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ğŸ˜Š
`;
```

### ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±

```javascript
// src/utils/promptBuilder.js
class PromptBuilder {
    constructor() {
        this.prompts = require('../config/prompts');
    }

    /**
     * ìƒí™©ë³„ ìµœì  í”„ë¡¬í”„íŠ¸ ìƒì„±
     */
    build(context) {
        const {
            questionType,
            userProfile,
            conversationHistory,
            relevantDocs,
            timeOfDay
        } = context;
        
        let prompt = this.prompts.SYSTEM_BASE;
        
        // ì§ˆë¬¸ ìœ í˜•ë³„ ì¶”ê°€
        if (questionType === 'technical') {
            prompt += '\n\n' + this.prompts.TECHNICAL_SUPPORT;
        } else if (questionType === 'as_request') {
            prompt += '\n\n' + this.prompts.AS_REQUEST;
        }
        
        // ì‚¬ìš©ì í”„ë¡œí•„ ë°˜ì˜
        if (userProfile) {
            prompt += `\n\n**ê³ ê° ì •ë³´:**\n`;
            prompt += `- ì´ë¦„: ${userProfile.name}\n`;
            prompt += `- ì´ì „ ë¬¸ì˜: ${userProfile.previousIssues}\n`;
        }
        
        // ì‹œê°„ëŒ€ë³„ ì¸ì‚¬
        const greeting = this._getTimeBasedGreeting(timeOfDay);
        prompt += `\n\n**ì¸ì‚¬ë§:** ${greeting}`;
        
        // ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
        if (conversationHistory && conversationHistory.length > 0) {
            prompt += '\n\n**ì´ì „ ëŒ€í™” ìš”ì•½:**\n';
            prompt += this._summarizeHistory(conversationHistory);
        }
        
        return prompt;
    }

    /**
     * ì‹œê°„ëŒ€ë³„ ì¸ì‚¬
     */
    _getTimeBasedGreeting(hour) {
        if (hour < 12) return 'ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤!';
        if (hour < 18) return 'ì•ˆë…•í•˜ì„¸ìš”!';
        return 'ì•ˆë…•í•˜ì„¸ìš”! ëŠ¦ì€ ì‹œê°„ê¹Œì§€ ìˆ˜ê³ í•˜ì‹­ë‹ˆë‹¤.';
    }

    /**
     * ëŒ€í™” ì´ë ¥ ìš”ì•½
     */
    _summarizeHistory(history) {
        const recent = history.slice(-3);
        return recent.map(h => `- ${h.role}: ${h.content.substring(0, 50)}...`).join('\n');
    }

    /**
     * RAG ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
     */
    formatRAGContext(documents) {
        if (!documents || documents.length === 0) {
            return null;
        }
        
        let context = '## ì°¸ê³  ë¬¸ì„œ\n\n';
        
        documents.forEach((doc, index) => {
            context += `### [ë¬¸ì„œ ${index + 1}] ${doc.metadata.source}\n`;
            context += `ê´€ë ¨ë„: ${doc.relevance}\n\n`;
            context += `${doc.content}\n\n`;
            context += `---\n\n`;
        });
        
        return context;
    }
}

module.exports = new PromptBuilder();
```

---

## ë¹„ìš© ìµœì í™”

### 1. ìºì‹± ì „ëµ

```javascript
// src/utils/cache.js
const Redis = require('redis');

class CacheService {
    constructor() {
        this.client = Redis.createClient({
            url: process.env.REDIS_URL || 'redis://localhost:6379'
        });
        this.client.connect();
        this.defaultTTL = 3600; // 1ì‹œê°„
    }

    /**
     * FAQ ìºì‹±
     */
    async cacheResponse(key, value, ttl = this.defaultTTL) {
        await this.client.setEx(key, ttl, JSON.stringify(value));
    }

    async getCachedResponse(key) {
        const cached = await this.client.get(key);
        return cached ? JSON.parse(cached) : null;
    }

    /**
     * ì§ˆë¬¸ ì •ê·œí™” (ìºì‹œ í‚¤ ìƒì„±)
     */
    normalizeQuestion(question) {
        return question
            .toLowerCase()
            .replace(/\s+/g, ' ')
            .replace(/[?!.]/g, '')
            .trim();
    }

    /**
     * ìŠ¤ë§ˆíŠ¸ ìºì‹± (ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰)
     */
    async findSimilarCached(question) {
        // ì •ê·œí™”ëœ ì§ˆë¬¸ìœ¼ë¡œ ìºì‹œ ê²€ìƒ‰
        const normalized = this.normalizeQuestion(question);
        const cacheKey = `q:${normalized}`;
        
        return await this.getCachedResponse(cacheKey);
    }
}

module.exports = new CacheService();
```

### 2. í† í° ìµœì í™”

```javascript
// í† í° ê³„ì‚° ë° ìµœì í™”
class TokenOptimizer {
    /**
     * í† í° ìˆ˜ ì¶”ì • (ëŒ€ëµ 4ì = 1í† í°)
     */
    estimateTokens(text) {
        return Math.ceil(text.length / 4);
    }

    /**
     * ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
     */
    truncateContext(context, maxTokens = 2000) {
        let totalTokens = 0;
        const truncated = [];
        
        for (const doc of context) {
            const docTokens = this.estimateTokens(doc.content);
            if (totalTokens + docTokens > maxTokens) {
                break;
            }
            truncated.push(doc);
            totalTokens += docTokens;
        }
        
        return truncated;
    }

    /**
     * ëŒ€í™” ì´ë ¥ ì••ì¶•
     */
    compressHistory(history, maxTurns = 5) {
        // ìµœê·¼ Ní„´ë§Œ ìœ ì§€
        const recent = history.slice(-maxTurns);
        
        // ê¸´ ë©”ì‹œì§€ ìš”ì•½
        return recent.map(msg => ({
            ...msg,
            content: msg.content.substring(0, 200) + (msg.content.length > 200 ? '...' : '')
        }));
    }
}

module.exports = new TokenOptimizer();
```

### 3. ë¹„ìš© ëª¨ë‹ˆí„°ë§

```javascript
// src/utils/costMonitor.js
class CostMonitor {
    constructor() {
        this.dailyCosts = new Map();
        this.alertThreshold = parseFloat(process.env.DAILY_COST_LIMIT) || 100; // $100
    }

    /**
     * ë¹„ìš© ê¸°ë¡
     */
    async recordCost(provider, usage, cost) {
        const today = new Date().toISOString().split('T')[0];
        
        if (!this.dailyCosts.has(today)) {
            this.dailyCosts.set(today, {
                total: 0,
                byProvider: {},
                requests: 0
            });
        }
        
        const dailyData = this.dailyCosts.get(today);
        dailyData.total += cost.total;
        dailyData.requests += 1;
        
        if (!dailyData.byProvider[provider]) {
            dailyData.byProvider[provider] = 0;
        }
        dailyData.byProvider[provider] += cost.total;
        
        // ì„ê³„ê°’ ì²´í¬
        if (dailyData.total >= this.alertThreshold) {
            await this.sendAlert(dailyData);
        }
        
        // DBì— ì €ì¥
        await this.saveToDB({
            date: today,
            provider: provider,
            usage: usage,
            cost: cost
        });
    }

    /**
     * ì•Œë¦¼ ì „ì†¡
     */
    async sendAlert(data) {
        console.error('[ë¹„ìš© ê²½ê³ ] ì¼ì¼ í•œë„ ì´ˆê³¼!', data);
        // ì´ë©”ì¼/ìŠ¬ë™ ì•Œë¦¼ ë“±
    }

    /**
     * ë¹„ìš© ë¦¬í¬íŠ¸
     */
    generateReport(period = 'daily') {
        // ë¹„ìš© ë¦¬í¬íŠ¸ ìƒì„±
    }
}

module.exports = new CostMonitor();
```

---

## ë³´ì•ˆ ë° ëª¨ë‹ˆí„°ë§

### 1. API í‚¤ ë³´ì•ˆ

```javascript
// src/config/security.js
const crypto = require('crypto');

class SecurityManager {
    /**
     * í™˜ê²½ ë³€ìˆ˜ ì•”í˜¸í™”
     */
    encryptAPIKey(apiKey) {
        const algorithm = 'aes-256-cbc';
        const key = process.env.ENCRYPTION_KEY;
        const iv = crypto.randomBytes(16);
        
        const cipher = crypto.createCipheriv(algorithm, key, iv);
        let encrypted = cipher.update(apiKey, 'utf8', 'hex');
        encrypted += cipher.final('hex');
        
        return {
            encrypted: encrypted,
            iv: iv.toString('hex')
        };
    }

    /**
     * ë³µí˜¸í™”
     */
    decryptAPIKey(encrypted, ivHex) {
        const algorithm = 'aes-256-cbc';
        const key = process.env.ENCRYPTION_KEY;
        const iv = Buffer.from(ivHex, 'hex');
        
        const decipher = crypto.createDecipheriv(algorithm, key, iv);
        let decrypted = decipher.update(encrypted, 'hex', 'utf8');
        decrypted += decipher.final('utf8');
        
        return decrypted;
    }

    /**
     * ìš”ì²­ ì¸ì¦
     */
    async authenticateRequest(req) {
        const token = req.headers.authorization?.split(' ')[1];
        
        if (!token) {
            throw new Error('ì¸ì¦ í† í° ì—†ìŒ');
        }
        
        // JWT ê²€ì¦ ë˜ëŠ” API í‚¤ ê²€ì¦
        const isValid = await this.verifyToken(token);
        
        if (!isValid) {
            throw new Error('ìœ íš¨í•˜ì§€ ì•Šì€ í† í°');
        }
        
        return true;
    }

    /**
     * Rate Limiting
     */
    async checkRateLimit(userId) {
        const key = `rate_limit:${userId}`;
        const limit = 100; // ì‹œê°„ë‹¹ 100íšŒ
        const current = await redis.incr(key);
        
        if (current === 1) {
            await redis.expire(key, 3600); // 1ì‹œê°„
        }
        
        if (current > limit) {
            throw new Error('ìš”ì²­ í•œë„ ì´ˆê³¼');
        }
        
        return {
            remaining: limit - current,
            resetAt: Date.now() + 3600000
        };
    }
}

module.exports = new SecurityManager();
```

### 2. ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§

```javascript
// src/utils/logger.js
const winston = require('winston');

const logger = winston.createLogger({
    level: process.env.LOG_LEVEL || 'info',
    format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.json()
    ),
    transports: [
        new winston.transports.File({ filename: 'logs/error.log', level: 'error' }),
        new winston.transports.File({ filename: 'logs/combined.log' }),
        new winston.transports.Console({
            format: winston.format.simple()
        })
    ]
});

/**
 * ëŒ€í™” ë¡œê¹…
 */
async function logConversation(data) {
    logger.info('Conversation', {
        userId: data.userId,
        question: data.question,
        answerLength: data.answer.length,
        model: data.model,
        cost: data.cost,
        timestamp: data.timestamp,
        relevantDocsCount: data.relevantDocsCount
    });
    
    // ë°ì´í„°ë² ì´ìŠ¤ì—ë„ ì €ì¥
    await saveToDatabase(data);
}

/**
 * ì—ëŸ¬ ë¡œê¹…
 */
function logError(error, context) {
    logger.error('Error occurred', {
        message: error.message,
        stack: error.stack,
        context: context,
        timestamp: new Date()
    });
}

module.exports = {
    logger,
    logConversation,
    logError
};
```

### 3. ë¯¼ê°ì •ë³´ í•„í„°ë§

```javascript
// src/utils/sanitizer.js
class DataSanitizer {
    /**
     * ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹
     */
    maskPersonalInfo(text) {
        // ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
        text = text.replace(/(\d{3})-?(\d{4})-?(\d{4})/g, '$1-****-$3');
        
        // ì´ë©”ì¼ ë§ˆìŠ¤í‚¹
        text = text.replace(/([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})/g, 
            (match, p1, p2) => {
                const masked = p1.substring(0, 2) + '***';
                return `${masked}@${p2}`;
            });
        
        // ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
        text = text.replace(/(\d{6})-?([1-4]\d{6})/g, '$1-*******');
        
        return text;
    }

    /**
     * SQL Injection ë°©ì§€
     */
    sanitizeInput(input) {
        // íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
        return input
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#x27;')
            .replace(/\//g, '&#x2F;');
    }

    /**
     * í”„ë¡¬í”„íŠ¸ ì¸ì ì…˜ ë°©ì§€
     */
    preventPromptInjection(userInput) {
        // ìœ„í—˜í•œ íŒ¨í„´ ê²€ì‚¬
        const dangerousPatterns = [
            /ignore previous instructions/i,
            /system prompt/i,
            /you are now/i,
            /forget everything/i
        ];
        
        for (const pattern of dangerousPatterns) {
            if (pattern.test(userInput)) {
                throw new Error('ë¶€ì ì ˆí•œ ì…ë ¥ ê°ì§€');
            }
        }
        
        return userInput;
    }
}

module.exports = new DataSanitizer();
```

---

## ë°°í¬ ë° ìš´ì˜

### Docker ë°°í¬

```dockerfile
# Dockerfile
FROM node:18-alpine

WORKDIR /app

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
COPY package*.json ./
RUN npm ci --only=production

# ì†ŒìŠ¤ ë³µì‚¬
COPY . .

# í™˜ê²½ ë³€ìˆ˜
ENV NODE_ENV=production

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 3000

# ì‹¤í–‰
CMD ["node", "src/index.js"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  chatbot-api:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
      - postgres
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=chatbot_db
      - POSTGRES_USER=chatbot
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  redis_data:
  postgres_data:
```

---

## ì°¸ê³  ìë£Œ

- [[ì œì‘ê°€ì´ë“œ|ì¹´ì¹´ì˜¤í†¡ ì±—ë´‡ ì œì‘ ê°€ì´ë“œ]]
- [[ChatGPT êµ¬ì¶• ê°€ì´ë“œ|ChatGPT ì—°ë™ ê°€ì´ë“œ]]
- [[Gemini ì—°êµ¬ ìë£Œ|Gemini API ì—°êµ¬]]
- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Anthropic Claude API](https://docs.anthropic.com/)
- [Google AI Gemini](https://ai.google.dev/)

---

## ì—…ë°ì´íŠ¸ ì´ë ¥

- **2025-10-17**: ì´ˆì•ˆ ì‘ì„± (OpenAI, Claude, Gemini ì—°ë™ ê°€ì´ë“œ)
- **ì˜ˆì •**: RAG ê³ ë„í™”, ì„±ëŠ¥ ìµœì í™” íŒ ì¶”ê°€


